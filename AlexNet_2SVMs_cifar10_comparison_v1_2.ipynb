{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet_2SVMs_cifar10_comparison_v1.2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDhOixs5TI9w"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "# import re\n",
        "# import random\n",
        "import keras\n",
        "import scipy\n",
        "import scipy.stats\n",
        "import sklearn\n",
        "from sklearn import svm\n",
        "# from sklearn.model_selection import train_test_split\n",
        "import json\n",
        "from datetime import datetime\n",
        "import keras.backend as K\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1cuVNvHVLlY",
        "outputId": "8e539cc7-1677-4b42-a78e-561d7dac6ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "######################################################################################\n",
        "##### DATA fetching #####\n",
        "######################################################################################\n",
        "\n",
        "# cifar_10_data = tf.keras.datasets.cifar10.load_data()\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "# data -- a 10000x3072 numpy array of uint8s. Each row of the array stores a 32x32 colour image. \n",
        "#         The first 1024 entries contain the red channel values, the next 1024 the green, and the final 1024 the blue. \n",
        "#         The image is stored in row-major order, so that the first 32 entries of the array are the red channel values of the first row of the image.\n",
        "# labels -- a list of 10000 numbers in the range 0-9. The number at index i indicates the label of the ith image in the array data.\n",
        "\n",
        "print(\"X_Train: \", x_train.shape)\n",
        "print(\"Y_Train: \", y_train.shape)\n",
        "print(\"X_Test: \", x_test.shape)\n",
        "print(\"Y_Test: \", y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "X_Train:  (50000, 32, 32, 3)\n",
            "Y_Train:  (50000, 1)\n",
            "X_Test:  (10000, 32, 32, 3)\n",
            "Y_Test:  (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U-LkKFMTiZo"
      },
      "source": [
        "# AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-7Tg4gbZoDJ"
      },
      "source": [
        "######################################################################################\n",
        "##### PARAMETERS #####\n",
        "######################################################################################\n",
        "\n",
        "no_of_labels = len(np.unique(y_train))\n",
        "input_shape = (x_train.shape[1],x_train.shape[2],x_train.shape[3])\n",
        "\n",
        "learning_rate = 0.001\n",
        "loss = \"categorical_crossentropy\"\n",
        "\n",
        "epochs = 25\n",
        "batch_size = 100\n",
        "validation_split = 0.2"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dsv9wkluoq9U"
      },
      "source": [
        "######################################################################################\n",
        "##### Preparing Y data for model #####\n",
        "######################################################################################\n",
        "\n",
        "y_train_input = np.zeros(shape=(y_train.shape[0],no_of_labels))\n",
        "for row in range(y_train.shape[0]):\n",
        "  y_train_input[row][y_train[row][0]] = 1\n",
        "\n",
        "y_test_input = np.zeros(shape=(y_test.shape[0],no_of_labels))\n",
        "for row in range(y_test.shape[0]):\n",
        "  y_test_input[row][y_test[row][0]] = 1"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq5nqUEfZkIk",
        "outputId": "4b67351b-0a35-4007-bdc2-95e18a4c6f1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Initializing MODEL #####\n",
        "######################################################################################\n",
        "\n",
        "model = keras.models.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(96, (5,5), strides = (2,2), activation = 'relu', input_shape = input_shape))\n",
        "# model.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(256, (3,3), strides = (1,1), activation = 'relu', padding = \"same\"))\n",
        "# model.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(384, (2,2), strides = (1,1), activation = 'relu', padding = \"same\"))\n",
        "# model.add(keras.layers.BatchNormalization(trainable = True))\n",
        "\n",
        "model.add(keras.layers.Conv2D(384, (2,2), strides = (1,1), activation = 'relu', padding = \"same\"))\n",
        "# model.add(keras.layers.BatchNormalization(trainable = True))\n",
        "\n",
        "model.add(keras.layers.Conv2D(256, (2,2), strides=(1,1), activation = 'relu', padding = \"same\"))\n",
        "# model.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
        "\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "model.add(keras.layers.Dense(256, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(256, activation = 'relu'))\n",
        "model.add(keras.layers.Dense(no_of_labels, activation = 'softmax'))\n",
        "\n",
        "model.compile(optimizer = keras.optimizers.Adam(learning_rate = learning_rate), loss = loss, metrics = ['BinaryAccuracy'])\n",
        "\n",
        "model.build()\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 96)        7296      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 7, 7, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 7, 7, 256)         221440    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 6, 6, 384)         393600    \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 6, 6, 384)         590208    \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 256)         393472    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6400)              0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 256)               1638656   \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                2570      \n",
            "=================================================================\n",
            "Total params: 3,313,034\n",
            "Trainable params: 3,313,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqoniicjcoHI",
        "outputId": "fe57b212-3905-4c4c-e3f4-d3b1ddb33602",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Training MODEL #####\n",
        "######################################################################################\n",
        "\n",
        "print(\"Training start time : \"+str(datetime.now()))\n",
        "\n",
        "## Model Fitting on Train Data\n",
        "model.fit(x_train, y_train_input, epochs = epochs, validation_split = validation_split, batch_size = batch_size, verbose = 1)\n",
        "# es_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "print(\"Training end time : \"+str(datetime.now()))\n",
        "\n",
        "model.save(\"main_model.h5\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training start time : 2020-10-24 08:17:46.008129\n",
            "Epoch 1/25\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.9655 - binary_accuracy: 0.9049WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0016s vs `on_test_batch_end` time: 0.0028s). Check your callbacks.\n",
            "400/400 [==============================] - 6s 15ms/step - loss: 1.9655 - binary_accuracy: 0.9049 - val_loss: 1.5063 - val_binary_accuracy: 0.9107\n",
            "Epoch 2/25\n",
            "400/400 [==============================] - 6s 15ms/step - loss: 1.3604 - binary_accuracy: 0.9175 - val_loss: 1.3182 - val_binary_accuracy: 0.9201\n",
            "Epoch 3/25\n",
            "400/400 [==============================] - 6s 15ms/step - loss: 1.1968 - binary_accuracy: 0.9261 - val_loss: 1.2439 - val_binary_accuracy: 0.9235\n",
            "Epoch 4/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 1.0713 - binary_accuracy: 0.9330 - val_loss: 1.1108 - val_binary_accuracy: 0.9309\n",
            "Epoch 5/25\n",
            "400/400 [==============================] - 6s 15ms/step - loss: 0.9707 - binary_accuracy: 0.9386 - val_loss: 1.0401 - val_binary_accuracy: 0.9354\n",
            "Epoch 6/25\n",
            "400/400 [==============================] - 6s 15ms/step - loss: 0.8907 - binary_accuracy: 0.9432 - val_loss: 1.0492 - val_binary_accuracy: 0.9354\n",
            "Epoch 7/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.8192 - binary_accuracy: 0.9474 - val_loss: 1.0182 - val_binary_accuracy: 0.9390\n",
            "Epoch 8/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.7658 - binary_accuracy: 0.9505 - val_loss: 0.9864 - val_binary_accuracy: 0.9393\n",
            "Epoch 9/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.6961 - binary_accuracy: 0.9545 - val_loss: 0.9619 - val_binary_accuracy: 0.9417\n",
            "Epoch 10/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.6414 - binary_accuracy: 0.9582 - val_loss: 0.9967 - val_binary_accuracy: 0.9407\n",
            "Epoch 11/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.6083 - binary_accuracy: 0.9604 - val_loss: 1.0010 - val_binary_accuracy: 0.9410\n",
            "Epoch 12/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.5932 - binary_accuracy: 0.9611 - val_loss: 1.0325 - val_binary_accuracy: 0.9410\n",
            "Epoch 13/25\n",
            "400/400 [==============================] - 7s 16ms/step - loss: 0.5198 - binary_accuracy: 0.9654 - val_loss: 1.0937 - val_binary_accuracy: 0.9383\n",
            "Epoch 14/25\n",
            "400/400 [==============================] - 7s 16ms/step - loss: 0.4716 - binary_accuracy: 0.9686 - val_loss: 1.2042 - val_binary_accuracy: 0.9377\n",
            "Epoch 15/25\n",
            "400/400 [==============================] - 7s 16ms/step - loss: 0.4449 - binary_accuracy: 0.9706 - val_loss: 1.1694 - val_binary_accuracy: 0.9404\n",
            "Epoch 16/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.4287 - binary_accuracy: 0.9713 - val_loss: 1.1741 - val_binary_accuracy: 0.9405\n",
            "Epoch 17/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.3782 - binary_accuracy: 0.9748 - val_loss: 1.2040 - val_binary_accuracy: 0.9408\n",
            "Epoch 18/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.3625 - binary_accuracy: 0.9759 - val_loss: 1.2088 - val_binary_accuracy: 0.9404\n",
            "Epoch 19/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.3273 - binary_accuracy: 0.9782 - val_loss: 1.2506 - val_binary_accuracy: 0.9397\n",
            "Epoch 20/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.3051 - binary_accuracy: 0.9798 - val_loss: 1.3536 - val_binary_accuracy: 0.9382\n",
            "Epoch 21/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.2805 - binary_accuracy: 0.9813 - val_loss: 1.4300 - val_binary_accuracy: 0.9406\n",
            "Epoch 22/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.2791 - binary_accuracy: 0.9817 - val_loss: 1.3997 - val_binary_accuracy: 0.9379\n",
            "Epoch 23/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.2519 - binary_accuracy: 0.9835 - val_loss: 1.3890 - val_binary_accuracy: 0.9360\n",
            "Epoch 24/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.2325 - binary_accuracy: 0.9846 - val_loss: 1.5266 - val_binary_accuracy: 0.9362\n",
            "Epoch 25/25\n",
            "400/400 [==============================] - 6s 16ms/step - loss: 0.2460 - binary_accuracy: 0.9837 - val_loss: 1.4574 - val_binary_accuracy: 0.9389\n",
            "Training end time : 2020-10-24 08:20:32.568499\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WNhTGQ0aPY6N",
        "outputId": "6763a652-ac1b-43cc-90db-2e99d4beccbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Generate prediction and performance metrics using Train Data (SEEN Data)\n",
        "######################################################################################\n",
        "\n",
        "train_prediction_output = model.predict(x_train)\n",
        "\n",
        "## train data prediction mapped to class with highest output value\n",
        "y_train_prediction_output = np.empty(shape=(y_train.shape[0]))\n",
        "for row in range(train_prediction_output.shape[0]):\n",
        "  y_train_prediction_output[row] = np.where(train_prediction_output[row] == np.amax(train_prediction_output[row]))[0][0]\n",
        "\n",
        "## reshaping y_train to required format\n",
        "y_train_reshaped = np.reshape(y_train, y_train.shape[0])\n",
        "\n",
        "confusion_df = pd.DataFrame({'y_true':y_train_reshaped, 'y_pred':y_train_prediction_output})\n",
        "confusion_df['comparison'] = (confusion_df['y_true'] == confusion_df['y_pred']).astype(int)\n",
        "print(\"=== For Train Data ===\")\n",
        "print(\"Total accuracy: \",sum(confusion_df['comparison'])/confusion_df.shape[0])\n",
        "\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_train_reshaped, y_train_prediction_output)\n",
        "confusion_matrix_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "print(\"Class wise accuracies: \")\n",
        "confusion_matrix_normalized.diagonal()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== For Train Data ===\n",
            "Total accuracy:  0.87962\n",
            "Class wise accuracies: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9268, 0.9318, 0.8166, 0.7444, 0.8318, 0.8486, 0.8862, 0.956 ,\n",
              "       0.9276, 0.9264])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_nR3IfwlOgP",
        "outputId": "ef880d21-f973-46c1-d4e8-1e7fffd5101a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Generate prediction and performance metrics using Test Data (UNSEEN Data)\n",
        "######################################################################################\n",
        "\n",
        "test_prediction_output = model.predict(x_test)\n",
        "\n",
        "## TEST data prediction mapped to class with highest output value\n",
        "y_test_prediction_output = np.empty(shape=(y_test.shape[0]))\n",
        "for row in range(test_prediction_output.shape[0]):\n",
        "  y_test_prediction_output[row] = np.where(test_prediction_output[row] == np.amax(test_prediction_output[row]))[0][0]\n",
        "\n",
        "## reshaping y_test to required format\n",
        "y_test_reshaped = np.reshape(y_test, y_test.shape[0])\n",
        "\n",
        "confusion_df = pd.DataFrame({'y_true':y_test_reshaped, 'y_pred':y_test_prediction_output})\n",
        "confusion_df['comparison'] = (confusion_df['y_true'] == confusion_df['y_pred']).astype(int)\n",
        "print(\"=== For Test Data ===\")\n",
        "print(\"Total accuracy: \",sum(confusion_df['comparison'])/confusion_df.shape[0])\n",
        "\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_test_reshaped, y_test_prediction_output)\n",
        "confusion_matrix_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "print(\"Class wise accuracies: \")\n",
        "confusion_matrix_normalized.diagonal()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== For Test Data ===\n",
            "Total accuracy:  0.6684\n",
            "Class wise accuracies: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.772, 0.8  , 0.482, 0.405, 0.557, 0.583, 0.722, 0.796, 0.783,\n",
              "       0.784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kg1zDv-TwP-"
      },
      "source": [
        "# SVM - 1\n",
        "##### Extracting model embeddings at the flattening layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mu3uUBCIOsIG",
        "outputId": "fad63170-d336-446b-ed5a-9a0244c107f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "K.clear_session()\n",
        "\n",
        "######################################################################################\n",
        "##### Extract sub-network trained AlexNet for embedding extraction\n",
        "######################################################################################\n",
        "\n",
        "## DEFINE the model sub-structure as required\n",
        "model_svm1_embedding = keras.models.Sequential()\n",
        "\n",
        "model_svm1_embedding.add(keras.layers.Conv2D(96, (5,5), strides = (2,2), activation = 'relu', input_shape = input_shape))\n",
        "# model_svm1_embedding.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model_svm1_embedding.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
        "\n",
        "model_svm1_embedding.add(keras.layers.Conv2D(256, (3,3), strides = (1,1), activation = 'relu', padding = \"same\"))\n",
        "# model_svm1_embedding.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model_svm1_embedding.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
        "\n",
        "## extract weight from already trained AlexNet to compile the new partial network for embedding extraction\n",
        "i = 0\n",
        "for layer in model_svm1_embedding.layers:\n",
        "  layer.set_weights(model.layers[i].get_weights())\n",
        "  i = i+1\n",
        "\n",
        "model_svm1_embedding.add(keras.layers.Flatten())\n",
        "\n",
        "model_svm1_embedding.compile(optimizer = keras.optimizers.Adam(learning_rate = learning_rate), loss = loss, metrics = ['BinaryAccuracy'])\n",
        "\n",
        "model_svm1_embedding.build()\n",
        "model_svm1_embedding.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 14, 14, 96)        7296      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 7, 7, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 256)         221440    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "=================================================================\n",
            "Total params: 228,736\n",
            "Trainable params: 228,736\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh-1JxF3UYQE"
      },
      "source": [
        "######################################################################################\n",
        "##### Generate the embeddings for the train and test feature sets\n",
        "######################################################################################\n",
        "\n",
        "x_train_svm1 = model_svm1_embedding.predict(x_train)\n",
        "x_test_svm1 = model_svm1_embedding.predict(x_test)\n",
        "\n",
        "## using y_train_reshaped and y_test_reshaped for SVM "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHyVTpTidGlt",
        "outputId": "b598269b-a932-451f-d657-1b767db2ddc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Training SVM model 1 #####\n",
        "######################################################################################\n",
        "\n",
        "svm_model_1 = svm.LinearSVC()\n",
        "\n",
        "## Train\n",
        "svm_model_1.fit(x_train_svm1, y_train_reshaped)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DzW7AFLd4Lb",
        "outputId": "a567c424-6665-4b5e-a1f1-4e77c822dda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Generate prediction and performance metrics using Train Data (SEEN Data)\n",
        "######################################################################################\n",
        "\n",
        "train_prediction_output = svm_model_1.predict(x_train_svm1)\n",
        "\n",
        "## reshaping y_train to required format\n",
        "y_train_reshaped = np.reshape(y_train, y_train.shape[0])\n",
        "\n",
        "confusion_df = pd.DataFrame({'y_true':y_train_reshaped, 'y_pred':train_prediction_output})\n",
        "confusion_df['comparison'] = (confusion_df['y_true'] == confusion_df['y_pred']).astype(int)\n",
        "print(\"=== For Train Data ===\")\n",
        "print(\"Total accuracy: \",sum(confusion_df['comparison'])/confusion_df.shape[0])\n",
        "\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_train_reshaped, train_prediction_output)\n",
        "confusion_matrix_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "print(\"Class wise accuracies: \")\n",
        "confusion_matrix_normalized.diagonal()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== For Train Data ===\n",
            "Total accuracy:  0.90848\n",
            "Class wise accuracies: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9084, 0.9922, 0.8968, 0.7152, 0.8704, 0.8756, 0.9634, 0.9226,\n",
              "       0.9916, 0.9486])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhnt50NU2WaP",
        "outputId": "8435b90a-58a7-40a7-d3a0-da4600150046",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Generate prediction and performance metrics using Test Data (SEEN Data)\n",
        "######################################################################################\n",
        "\n",
        "test_prediction_output = svm_model_1.predict(x_test_svm1)\n",
        "\n",
        "## reshaping y_test to required format\n",
        "y_test_reshaped = np.reshape(y_test, y_test.shape[0])\n",
        "\n",
        "confusion_df = pd.DataFrame({'y_true':y_test_reshaped, 'y_pred':test_prediction_output})\n",
        "confusion_df['comparison'] = (confusion_df['y_true'] == confusion_df['y_pred']).astype(int)\n",
        "print(\"=== For test Data ===\")\n",
        "print(\"Total accuracy: \",sum(confusion_df['comparison'])/confusion_df.shape[0])\n",
        "\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_test_reshaped, test_prediction_output)\n",
        "confusion_matrix_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "print(\"Class wise accuracies: \")\n",
        "confusion_matrix_normalized.diagonal()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== For test Data ===\n",
            "Total accuracy:  0.5665\n",
            "Class wise accuracies: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.582, 0.689, 0.52 , 0.322, 0.501, 0.484, 0.641, 0.61 , 0.706,\n",
              "       0.61 ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7iHLTH42xsN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egsac1CP3H3S"
      },
      "source": [
        "# SVM - 2\n",
        "##### Extracting model embeddings at the final dense layer before the last dense layer which has units equal to the number of different classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bOmS3PZ3H3W",
        "outputId": "5a552177-82be-4a94-c3f6-b134769c6c0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Extract sub-network trained AlexNet for embedding extraction\n",
        "######################################################################################\n",
        "\n",
        "## DEFINE the model sub-structure as required\n",
        "model_svm2_embedding = keras.models.Sequential()\n",
        "\n",
        "model_svm2_embedding.add(keras.layers.Conv2D(96, (5,5), strides = (2,2), activation = 'relu', input_shape = input_shape))\n",
        "# model_svm2_embedding.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model_svm2_embedding.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (2,2)))\n",
        "\n",
        "model_svm2_embedding.add(keras.layers.Conv2D(256, (3,3), strides = (1,1), activation = 'relu', padding = \"same\"))\n",
        "# model_svm2_embedding.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model_svm2_embedding.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
        "\n",
        "model_svm2_embedding.add(keras.layers.Conv2D(384, (2,2), strides = (1,1), activation = 'relu', padding = \"same\"))\n",
        "# model_svm2_embedding.add(keras.layers.BatchNormalization(trainable = True))\n",
        "\n",
        "model_svm2_embedding.add(keras.layers.Conv2D(384, (2,2), strides = (1,1), activation = 'relu', padding = \"same\"))\n",
        "# model_svm2_embedding.add(keras.layers.BatchNormalization(trainable = True))\n",
        "\n",
        "model_svm2_embedding.add(keras.layers.Conv2D(256, (2,2), strides=(1,1), activation = 'relu', padding = \"same\"))\n",
        "# model_svm2_embedding.add(keras.layers.BatchNormalization(trainable = True))\n",
        "model_svm2_embedding.add(keras.layers.MaxPooling2D(pool_size=(2,2), strides = (1,1)))\n",
        "\n",
        "## extract weight from already trained AlexNet to compile the new partial network for embedding extraction\n",
        "i = 0\n",
        "for layer in model_svm2_embedding.layers:\n",
        "  layer.set_weights(model.layers[i].get_weights())\n",
        "  i = i+1\n",
        "\n",
        "model_svm2_embedding.add(keras.layers.Flatten())\n",
        "\n",
        "model_svm2_embedding.compile(optimizer = keras.optimizers.Adam(learning_rate = learning_rate), loss = loss, metrics = ['BinaryAccuracy'])\n",
        "\n",
        "model_svm2_embedding.build()\n",
        "model_svm2_embedding.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 14, 14, 96)        7296      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 7, 7, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 7, 7, 256)         221440    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 6, 6, 384)         393600    \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 6, 6, 384)         590208    \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 6, 6, 256)         393472    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 5, 5, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6400)              0         \n",
            "=================================================================\n",
            "Total params: 1,606,016\n",
            "Trainable params: 1,606,016\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLY2vIPa3H3i"
      },
      "source": [
        "######################################################################################\n",
        "##### Generate the embeddings for the train and test feature sets\n",
        "######################################################################################\n",
        "\n",
        "x_train_svm2 = model_svm2_embedding.predict(x_train)\n",
        "x_test_svm2 = model_svm2_embedding.predict(x_test)\n",
        "\n",
        "## using y_train_reshaped and y_test_reshaped for SVM "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kteRBrtF3H3v",
        "outputId": "494045de-d4d8-440b-92f1-d39714db6a99",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Training SVM model 1 #####\n",
        "######################################################################################\n",
        "\n",
        "svm_model_2 = svm.LinearSVC()\n",
        "\n",
        "## Train\n",
        "svm_model_2.fit(x_train_svm2, y_train_reshaped)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
              "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
              "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
              "          verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A33m4tCF3H36",
        "outputId": "60a54e44-8ffd-42b6-d18d-4acf3e684998",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Generate prediction and performance metrics using Train Data (SEEN Data)\n",
        "######################################################################################\n",
        "\n",
        "train_prediction_output = svm_model_2.predict(x_train_svm2)\n",
        "\n",
        "## reshaping y_train to required format\n",
        "y_train_reshaped = np.reshape(y_train, y_train.shape[0])\n",
        "\n",
        "confusion_df = pd.DataFrame({'y_true':y_train_reshaped, 'y_pred':train_prediction_output})\n",
        "confusion_df['comparison'] = (confusion_df['y_true'] == confusion_df['y_pred']).astype(int)\n",
        "print(\"=== For Train Data ===\")\n",
        "print(\"Total accuracy: \",sum(confusion_df['comparison'])/confusion_df.shape[0])\n",
        "\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_train_reshaped, train_prediction_output)\n",
        "confusion_matrix_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "print(\"Class wise accuracies: \")\n",
        "confusion_matrix_normalized.diagonal()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== For Train Data ===\n",
            "Total accuracy:  0.97222\n",
            "Class wise accuracies: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9888, 0.997 , 0.9678, 0.9278, 0.9838, 0.901 , 0.9932, 0.9746,\n",
              "       0.9956, 0.9926])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cUwLVdQ3H4D",
        "outputId": "3deebb88-b610-4ab8-f0a0-bd5b957ddb1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "######################################################################################\n",
        "##### Generate prediction and performance metrics using Test Data (SEEN Data)\n",
        "######################################################################################\n",
        "\n",
        "test_prediction_output = svm_model_2.predict(x_test_svm2)\n",
        "\n",
        "## reshaping y_test to required format\n",
        "y_test_reshaped = np.reshape(y_test, y_test.shape[0])\n",
        "\n",
        "confusion_df = pd.DataFrame({'y_true':y_test_reshaped, 'y_pred':test_prediction_output})\n",
        "confusion_df['comparison'] = (confusion_df['y_true'] == confusion_df['y_pred']).astype(int)\n",
        "print(\"=== For test Data ===\")\n",
        "print(\"Total accuracy: \",sum(confusion_df['comparison'])/confusion_df.shape[0])\n",
        "\n",
        "confusion_matrix = sklearn.metrics.confusion_matrix(y_test_reshaped, test_prediction_output)\n",
        "confusion_matrix_normalized = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]\n",
        "print(\"Class wise accuracies: \")\n",
        "confusion_matrix_normalized.diagonal()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== For test Data ===\n",
            "Total accuracy:  0.6214\n",
            "Class wise accuracies: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.669, 0.746, 0.521, 0.439, 0.561, 0.464, 0.716, 0.65 , 0.752,\n",
              "       0.696])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1Dk16084VeV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
